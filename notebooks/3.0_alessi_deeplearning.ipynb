{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessitomas/Neural-Network-MNIST/blob/main/3.0_alessi_deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPKJmM20nRws"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m4e3EW5mFgQ"
      },
      "source": [
        "This notebook was created on google collab to access GPU, that's why it is importing the dataset once again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5afovgyslPZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65d780e-58a5-4c76-9d9d-d2612f7b7d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              " 0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " ...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              " 69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " \n",
              "        pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              " 0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " ...        ...  ...       ...       ...       ...       ...       ...   \n",
              " 69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " \n",
              "        pixel780  pixel781  pixel782  pixel783  pixel784  \n",
              " 0           0.0       0.0       0.0       0.0       0.0  \n",
              " 1           0.0       0.0       0.0       0.0       0.0  \n",
              " 2           0.0       0.0       0.0       0.0       0.0  \n",
              " 3           0.0       0.0       0.0       0.0       0.0  \n",
              " 4           0.0       0.0       0.0       0.0       0.0  \n",
              " ...         ...       ...       ...       ...       ...  \n",
              " 69995       0.0       0.0       0.0       0.0       0.0  \n",
              " 69996       0.0       0.0       0.0       0.0       0.0  \n",
              " 69997       0.0       0.0       0.0       0.0       0.0  \n",
              " 69998       0.0       0.0       0.0       0.0       0.0  \n",
              " 69999       0.0       0.0       0.0       0.0       0.0  \n",
              " \n",
              " [70000 rows x 784 columns],\n",
              " 0        5\n",
              " 1        0\n",
              " 2        4\n",
              " 3        1\n",
              " 4        9\n",
              "         ..\n",
              " 69995    2\n",
              " 69996    3\n",
              " 69997    4\n",
              " 69998    5\n",
              " 69999    6\n",
              " Name: class, Length: 70000, dtype: int8)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "\n",
        "# A função fetch_openml() retorna targets como strings, precisamos converter para\n",
        "# valores numéricos.\n",
        "mnist.target = mnist.target.astype(np.int8)\n",
        "\n",
        "mnist[\"data\"], mnist[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = mnist['data'].to_numpy(), mnist['target'].to_numpy()"
      ],
      "metadata": {
        "id": "cTdIcX7W4KBx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHktU4KfnOlU"
      },
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyBx2lFonNhY"
      },
      "source": [
        "This method of splitting was suggest by the creators of the dataset: \"It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples\", Reference: [OpenML Dataset](https://www.openml.org/search?type=data&sort=runs&id=554&status=active)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rc2nqZSclsmh"
      },
      "outputs": [],
      "source": [
        "X_train = X[:60000]\n",
        "y_train = y[:60000]\n",
        "\n",
        "X_test = X[60000:]\n",
        "y_test = y[60000:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzeIH5mD0Hfl",
        "outputId": "4647550f-3fd6-4ad3-ac72-211ec98e5a92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSqAIPc40M8G",
        "outputId": "315c5c3e-ec9f-4999-f156-ba041b8fbd1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orl4ZC7hnXFl"
      },
      "source": [
        "## DeepLearning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 - Uses Artificial Neural Networks to mimic human brain. Consited of layers of conected neurons that work together to learn an process information.\n",
        "\n",
        "1.2 - Neuron in a simple manner (Node that keeps a number, its activity)\n",
        "\n",
        "1.3 - A activation of a neurons on a previous layer will determine the activation of neurons on the next layer"
      ],
      "metadata": {
        "id": "HFt3n5nkh72y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yZjvmkLnWqz",
        "outputId": "80606123-f64c-44e8-cb25-6988d5f936aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The notebook is using the: GPU\n"
          ]
        }
      ],
      "source": [
        "# First i will check if google's collab GPU is available\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"The notebook is using the: GPU\")\n",
        "else:\n",
        "    print(\"The notebook is using the: CPU\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Math Concepts"
      ],
      "metadata": {
        "id": "a68rQR4GobAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing a Fully Connected Layer:\n",
        "\n",
        "\n",
        "\n",
        "Equation to calculate the activity of a neuron:\n",
        "\n",
        "a<sup>(1)</sup> = b + w<sub>1</sub>a<sup>(0)</sup> + w<sub>2</sub>a<sup>(0)</sup> + w<sub>3</sub>a<sup>(0)</sup> + ... + w<sub>n</sub>a<sup>(0)</sup>\n",
        "\n",
        "Now with the Matrix Notation to calculate the activity of all neurons on a layer:\n",
        "\n",
        "\n",
        "$$\n",
        "Parameters =\n",
        "\\begin{bmatrix}\n",
        "    b_1 & w(1,1) & w(2,1) & \\ldots & w(n,1) \\\\\n",
        "    b_2 & w(1,2) & w(2,2) & \\ldots & w(n,2) \\\\\n",
        "    b_3 & w(1,3) & w(2,3) & \\ldots & w(n,3) \\\\\n",
        "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    b_k & w(1,k) & w(2,k) & \\ldots & w(n,k) \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "$$\n",
        "NeuronsLayer(0) =\n",
        "\\begin{bmatrix}\n",
        "    1 \\\\\n",
        "    1a^{(0)} \\\\\n",
        "    2a^{(0)} \\\\\n",
        "    \\vdots \\\\\n",
        "    3a^{(0)}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "NeuronsLayer(1) = Parameters @ NeuronsLayer(0)\n",
        "\n",
        "This equation results on any continuous number, and in context where you need only the activity of a neuron, is common to pass a activity function on the equation results, like a Sigmoid or Rectified Linear Unit."
      ],
      "metadata": {
        "id": "0mEAHscXbMoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the ANN"
      ],
      "metadata": {
        "id": "eD2P2n7aoYpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Setting the device as a GPU, to process PyTorch operations\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# Creating my custom neural network architecture ANNModel\n",
        "class ANNModel(nn.Module):\n",
        "    # Constructor method\n",
        "    def __init__(self):\n",
        "        super(ANNModel, self).__init__() # Initializing the parent class nn.Module\n",
        "        self.input_layer = nn.Flatten() # Flat the input to a one dimensional vector\n",
        "        self.hidden_layer1 = nn.Linear(28 * 28, 256)  # Fully connected layer, sizes (input,output)\n",
        "        self.relu = nn.ReLU()\n",
        "        # self.sig = nn.Sigmoid()\n",
        "        self.hidden_layer2 = nn.Linear(256, 128)  # Fully connected layer, sizes (input,output)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output_layer = nn.Linear(128, 10)  # Fully connected layer, sizes (input,output)\n",
        "        # self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    # define the seq of operations from the input to the output\n",
        "    def forward(self, x):\n",
        "        x = self.input_layer(x)\n",
        "        x = self.hidden_layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.hidden_layer2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output_layer(x)\n",
        "        # x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "H7jOOSNM-Nsb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Process\n",
        "\n",
        "Learning is fiding the right parameters to minimise to cost function"
      ],
      "metadata": {
        "id": "gA9X1LuGoiIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropagation\n",
        "\n",
        "Equation to calculate the activity of a neuron:\n",
        "\n",
        "a<sup>(4)</sup> = b + w<sub>1</sub>a<sup>(3)</sup> + w<sub>2</sub>a<sup>(3)</sup> + w<sub>3</sub>a<sup>(3)</sup> + ... + w<sub>n</sub>a<sup>(3)</sup>\n",
        "\n",
        "Now, when we've computed the cost function and its gradients, it's essential to update the model's parameters. In this example, we're focusing on Layer 4 as the output layer. Upon closer examination of the equation, we can identify three key parameters that need to be updated: b (the bias term), and the various w weights associated with this layer.\n",
        "\n",
        "The parameter update process takes place layer by layer, starting from Layer 4 and moving backward to the input layer. This iterative process, where we adjust parameters layer by layer, is what gives rise to the term \"Backpropagation.\"\n"
      ],
      "metadata": {
        "id": "uODQyMMNt0vH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uBn3lWhvkTp1"
      },
      "outputs": [],
      "source": [
        "# Creating an instance of the ANN and conecting it to the device (gpu or cpu)\n",
        "model = ANNModel().to(device)\n",
        "\n",
        "# Loss function\n",
        "# criterion = nn.MSELoss()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Stochastic Gradient Descent (SGD), minises the loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Data to GPU\n",
        "X_train = torch.Tensor(X_train).to(device)\n",
        "y_train = torch.Tensor(y_train).to(device)\n",
        "X_test = torch.Tensor(X_test).to(device)\n",
        "y_test = torch.Tensor(y_test).to(device)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# Iterate thought all the training data set\n",
        "for epoch in range(epochs):\n",
        "    # Iterate thought X_train splitting it in batches\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        # Defining baches\n",
        "        inputs = X_train[i:i+batch_size]\n",
        "        labels = y_train[i:i+batch_size]\n",
        "\n",
        "        # Clears the gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Model predict\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calcualte the loss, of the predictions with the label\n",
        "        loss = criterion(outputs,labels.to(torch.int64))\n",
        "\n",
        "        # Backpropagation algorithm, compute the gradients of the loss of the parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Model"
      ],
      "metadata": {
        "id": "esevBCXHpldh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRJ0j54TpY9J",
        "outputId": "ebd4203a-a13a-47f0-8a13-5ef098bd325f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9573999643325806\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test data\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    accuracy = (torch.argmax(test_outputs, dim=1) == y_test.to(torch.int64)).float().mean().item()\n",
        "\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPceg2R1fOPVFc8sCD73Sd3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}